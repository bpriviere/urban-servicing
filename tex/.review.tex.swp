
\documentclass{article}

\usepackage{xcolor}
\usepackage{amsmath}

\begin{document}

\title{Account of changes: Urban Ridesharing with Hybrid Distributed Reinforcement Learning}

\author{Benjamin~Riviere,
        Salar~Rahili,
        and~Soon-Jo~Chung}

\maketitle

\section{Introduction}
As this review required a major revision of the originally submitted paper, we present this document in addition to the revised version for a full account of changes. In this document, we first present an overview of major changes, then a section for a detailed response to each of the reviewers, where their original comments are in bold and we address each point in the space below. We would like to thank the reviewers and the editor for their helpful feedback. 

\section{Major Changes}
In addressing the reviewers' feedback, we believe that we have addressed the main points as outlined by the editor
\begin{itemize}
	\item literature review and discussion of the methodological contributions of the paper in view of the literature
	\item inclusion of a fair comparison with state-of-the-art methods
	\item evaluation of the scalability of the method, for instance by including simulation results with different fleet size (large-scale performance)
	\item valuation of objective functions/performance indicators that are of interest from the transportation perspective: travel times, waiting times, delays (extra waiting and travel time due to the dynamic operation of the system), operating costs, etc.
	\item various clarifications of the proposed method
\end{itemize}

\newpage

\section{Reviewer 1}
\textcolor{red}{Reviewer: Regarding the prior, assignment for serving ridesharing requests is related to the mobility profiling of individuals. Mobility profiling with road network (e.g. POIs) is even richer: it predicts forthcoming demand by origin AND destination. Both are valuable in the optimization process of the automatic ride-matching process. However, no mobility (except OD), road network and traffic have been integrated into the MDP formulation.}

Authors: ??? not sure what he is talking about 


\textcolor{blue}{Reviewer: Regarding the latter, in my eyes, coordination would be much more interesting for this optimization of the allocation to vehicle capacity, rather than for the sharing of vehicles to reach common or nearby destinations. How to coordinate the schedules between participants, issue a ride-matching process to determine vehicle routes and the assignment of passengers to vehicles are critical ridesharing problems. Usually, we consider the objectives of maximizing the number of serviced passengers, minimizing the operating cost, and minimizing passenger inconvenience. I don't see many correlations to ridesharing here.}

Authors: Unfortunately, there is a miscommunication here (common among some of the reviewers). Our paper was never intended to be focused on coordinating schedules between participants in a carpooling fashion. I believe this miscommunication comes from the use of the word 'ridesharing'. As Uber describes themselves as a ridesharing company, we thought this was the appropriate word to use, but it seems to be misleading. \textcolor{red}{To address this comment, we have changed the title to Distributional Fleet Control something}. Actually changing the topic of this paper to carpooling would require an entirely new carpooling framework and analysis would be essentially be a new paper, thus we consider it outside the scope of this review.  


\textcolor{blue}{Reviewer: My questions are supported by the presented summary of the contributions of the paper on Page 2. Contribution 1 claims “MDP formulation for optimal routing” but fails to say how to pick up new passengers en-route or make a detour. It is unclear to me. The authors could provide a case study.}

Authors: Our method attempts to use an agent-based and cell-based approach. The MDP appeals to a cell-based approach, so it does not actually coordinate taxi-to-customer. Instead, it provides optimal distributions of taxis such that they can minimize expected discounted reward. Then, we rely on the game theory to use the cell-based information to coordinate individual taxis to customers. \textcolor{red}{To address this point, we have reformulated the MDP, and introduced a problem statement??}


\textcolor{blue}{Reviewer: This work seems to be an extension of the existing TD Q-learning algorithm to the transportation area. The authors may consider identifying the challenging issues in using reinforcement learning to solve the problem when people sharing a trip. Besides, for a fair comparison with others, using the existing reinforcement learning methods is a little bit insufficient. Some of the original studies in ridesharing should be also highlighted in the comparison.}

Authors: We have addressed 


Reviewer: The first paragraph of the introduction is irrelevant to the ridesharing problem at hand.

Authors: We have restructured the introduction, and removed large amounts of that original paragraph. 


Reviewer: Is a "multi-rider ridesharing"? have already multiple riders compromised on their schedules? Nothing is talking about multiple riders.

Authors: I believe we have addressed this comment earlier, in stating that we did not write a paper on coordinating multiple schedules, although the wording may have been misleading.  


Reviewer: What’s the “unknown environment”? this statement needs references.

Authors: By this, we mean that the reward model is unknown a priori. This makes traditional model-based methods like RHC from Pappas less applicable.


Reviewer: Why is ||(xti-ytj)-(xtj-ytj)||2<=Rc ?

Authors: I am not sure where this appears in the text, there is something close to that in the game theoretic section: $\|(x_t^i,y_t^j)-(x_t^j,y_t^j)\|2<=Rc$. Here we are writing (x,y) as a vector, and taking a standard distance metric to define a neighboring set of agents.  


Reviewer: The application of the proposed algorithm in online learning scenarios:
\begin{itemize}
	\item What assumptions are made in the Chicago taxis dataset?
	\item How might the proposed algorithm be applied/tested with real-time data?
	\item What might be the timeliness of assignment (i.e., horizons) - this would be critical to the performance of any future mobility system (refer to recent papers from Savelsbergh) – on-demand, dial-a-ride, etc.
	\item What challenges/benefits might exist here?
	\item Can parts of your algorithm be adapted to other ridesharing forms?
\end{itemize}

Authors: 
   	
Reviewer: I think the task assignment, is not sufficiently described. Some papers are cited in this area, but these are limited and there is little alignment with the manuscript about how these might be integrated, particularly in regard to trip purpose and utility. I'm confused about how this relates to traditional transport theory? Why aren’t other aspects of utility mentioned?
   	-Choice factors
   	-Choice hierarchies/temporal variability
   	-Concepts of Spatio-temporal flexibility
   	-Trust
   	-Other activities-based intentions
   	
   	Reviewer: If a system is suggesting ridesharing assignment based on dynamic demands, how might alternative actions be suggested? My choice factors/hierarchy may change with a range of outside effects (e.g., weather), and a broader choice set may be desirable for increased utility (refer recommender systems research).
   	
   	Reviewer: The parameters of algorithms were not discussed in detail.
   	Author: \textcolor{red}{To address this comment we added a more detailed algorithms and parameters discussion.}




\end{document}



