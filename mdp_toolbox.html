<!DOCTYPE html>
<!-- saved from url=(0058)https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html -->
<html class=" js flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths" lang="en" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Markov Decision Process (MDP) Toolbox: mdp module — Python Markov Decision Process Toolbox 4.0-b4 documentation</title>
  

  
  

  
  <link href="./mdp_toolbox_files/css" rel="stylesheet" type="text/css">

  
  
    

  

  
  

  
    <link rel="stylesheet" href="./mdp_toolbox_files/sphinx_rtd_theme.css" type="text/css">
  
    <link rel="stylesheet" href="./mdp_toolbox_files/readthedocs-doc-embed.css" type="text/css">
  

  
    <link rel="top" title="Python Markov Decision Process Toolbox 4.0-b4 documentation" href="https://pymdptoolbox.readthedocs.io/en/latest/index.html">
        <link rel="next" title="Markov Decision Process (MDP) Toolbox: util module" href="https://pymdptoolbox.readthedocs.io/en/latest/api/util.html">
        <link rel="prev" title="Markov Decision Process (MDP) Toolbox" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html">
 
<!-- RTD Extra Head -->



<!-- 
Read the Docs is acting as the canonical URL for your project. 
If you want to change it, more info is available in our docs:
  http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://pymdptoolbox.readthedocs.org/en/latest/api/mdp.html">

<script type="text/javascript" async="" src="./mdp_toolbox_files/ga.js"></script><script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "pymdptoolbox",
    version: "latest",
    language: "en",
    page: "api/mdp",
    builder: "sphinx",
    theme: "sphinx_rtd_theme",
    docroot: "/docs/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org",
    commit: "7c96789cc80e280437005c12065cf70266c11636"
  }
  // Old variables
  var doc_version = "latest";
  var doc_slug = "pymdptoolbox";
  var page_name = "api/mdp";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="./mdp_toolbox_files/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document" style="">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side"><div class="wy-side-scroll"><div class="wy-side-nav-search">
        
          <a href="https://pymdptoolbox.readthedocs.io/en/latest/index.html" class="fa fa-home"> Python Markov Decision Process Toolbox</a>
        
        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="https://pymdptoolbox.readthedocs.io/en/latest/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs">
    <input type="hidden" name="check_keywords" value="yes">
    <input type="hidden" name="area" value="default">
  </form>
</div>
      </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html"><span class="toctree-expand"></span>Markov Decision Process (MDP) Toolbox</a><ul>
<li class="toctree-l2"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html#available-modules">Available modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html#how-to-use-the-documentation">How to use the documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html#acknowledgments">Acknowledgments</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html"><span class="toctree-expand"></span>Markov Decision Process (MDP) Toolbox: <tt class="docutils literal"><span class="pre">mdp</span></tt> module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#available-classes">Available classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/util.html"><span class="toctree-expand"></span>Markov Decision Process (MDP) Toolbox: <tt class="docutils literal"><span class="pre">util</span></tt> module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/util.html#available-functions">Available functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/example.html"><span class="toctree-expand"></span>Markov Decision Process (MDP) Toolbox: <tt class="docutils literal"><span class="pre">example</span></tt> module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/example.html#available-functions">Available functions</a></li>
</ul>
</li>
</ul>

          
        
      </div><div id="rtd-lnbedep3" class="ethical-rtd ethical-dark-theme"></div><div id="rtd-br9l6gnt" class="keep-us-sustainable"><p>Support Read the Docs!</p><p>Please help keep us sustainable by <a href="https://docs.readthedocs.io/en/latest/advertising/ad-blocking.html#allowing-ethical-ads">allowing our Ethical Ads in your ad blocker</a> or <a href="https://readthedocs.org/sustainability/">go ad-free</a> by subscribing.</p><p>Thank you! ❤️</p></div></div>
      

      
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="https://pymdptoolbox.readthedocs.io/en/latest/index.html">Python Markov Decision Process Toolbox</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="https://pymdptoolbox.readthedocs.io/en/latest/index.html">Docs</a> »</li>
      
    <li>Markov Decision Process (MDP) Toolbox: <tt class="docutils literal"><span class="pre">mdp</span></tt> module</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/sawcordwell/pymdptoolbox/blob/master/docs/api/mdp.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr>
</div>
          <div role="main" class="document">
            
  <span class="target" id="module-mdptoolbox.mdp"></span><div class="section" id="markov-decision-process-mdp-toolbox-mdp-module">
<h1>Markov Decision Process (MDP) Toolbox: <tt class="docutils literal"><span class="pre">mdp</span></tt> module<a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#markov-decision-process-mdp-toolbox-mdp-module" title="Permalink to this headline">¶</a></h1>
<p>The <tt class="docutils literal"><span class="pre">mdp</span></tt> module provides classes for the resolution of descrete-time Markov
Decision Processes.</p>
<div class="section" id="available-classes">
<h2>Available classes<a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#available-classes" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="mdptoolbox.mdp.MDP"><tt class="xref py py-class docutils literal"><span class="pre">MDP</span></tt></a></dt>
<dd>Base Markov decision process class</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.FiniteHorizon" title="mdptoolbox.mdp.FiniteHorizon"><tt class="xref py py-class docutils literal"><span class="pre">FiniteHorizon</span></tt></a></dt>
<dd>Backwards induction finite horizon MDP</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIteration" title="mdptoolbox.mdp.PolicyIteration"><tt class="xref py py-class docutils literal"><span class="pre">PolicyIteration</span></tt></a></dt>
<dd>Policy iteration MDP</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIterationModified" title="mdptoolbox.mdp.PolicyIterationModified"><tt class="xref py py-class docutils literal"><span class="pre">PolicyIterationModified</span></tt></a></dt>
<dd>Modified policy iteration MDP</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.QLearning" title="mdptoolbox.mdp.QLearning"><tt class="xref py py-class docutils literal"><span class="pre">QLearning</span></tt></a></dt>
<dd>Q-learning MDP</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.RelativeValueIteration" title="mdptoolbox.mdp.RelativeValueIteration"><tt class="xref py py-class docutils literal"><span class="pre">RelativeValueIteration</span></tt></a></dt>
<dd>Relative value iteration MDP</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIteration" title="mdptoolbox.mdp.ValueIteration"><tt class="xref py py-class docutils literal"><span class="pre">ValueIteration</span></tt></a></dt>
<dd>Value iteration MDP</dd>
<dt><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIterationGS" title="mdptoolbox.mdp.ValueIterationGS"><tt class="xref py py-class docutils literal"><span class="pre">ValueIterationGS</span></tt></a></dt>
<dd>Gauss-Seidel value iteration MDP</dd>
</dl>
<dl class="class">
<dt id="mdptoolbox.mdp.FiniteHorizon">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">FiniteHorizon</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>N</em>, <em>h=None</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#FiniteHorizon"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.FiniteHorizon" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="mdptoolbox.mdp.MDP"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.MDP</span></tt></a></p>
<p>A MDP solved using the finite-horizon backwards induction algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.</li>
<li><strong>N</strong> (<em>int</em>) – Number of periods. Must be greater than 0.</li>
<li><strong>h</strong> (<em>array, optional</em>) – Terminal reward. Default: a vector of zeros.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attributes</strong> (<em>Data</em>) – </li>
<li><strong>—————</strong> – </li>
<li><strong>V</strong> (<em>array</em>) – Optimal value function. Shape = (S, N+1). <tt class="docutils literal"><span class="pre">V[:,</span> <span class="pre">n]</span></tt> = optimal value
function at stage <tt class="docutils literal"><span class="pre">n</span></tt> with stage in {0, 1...N-1}. <tt class="docutils literal"><span class="pre">V[:,</span> <span class="pre">N]</span></tt> value
function for terminal stage.</li>
<li><strong>policy</strong> (<em>array</em>) – Optimal policy. <tt class="docutils literal"><span class="pre">policy[:,</span> <span class="pre">n]</span></tt> = optimal policy at stage <tt class="docutils literal"><span class="pre">n</span></tt> with
stage in {0, 1...N}. <tt class="docutils literal"><span class="pre">policy[:,</span> <span class="pre">N]</span></tt> = policy for stage <tt class="docutils literal"><span class="pre">N</span></tt>.</li>
<li><strong>time</strong> (<em>float</em>) – used CPU time</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>In verbose mode, displays the current stage and policy transpose.</p>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span><span class="o">,</span> <span class="nn">mdptoolbox.example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">forest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fh</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">FiniteHorizon</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fh</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fh</span><span class="o">.</span><span class="n">V</span>
<span class="go">array([[ 2.6973,  0.81  ,  0.    ,  0.    ],</span>
<span class="go">       [ 5.9373,  3.24  ,  1.    ,  0.    ],</span>
<span class="go">       [ 9.9373,  7.24  ,  4.    ,  0.    ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fh</span><span class="o">.</span><span class="n">policy</span>
<span class="go">array([[0, 0, 0],</span>
<span class="go">       [0, 0, 1],</span>
<span class="go">       [0, 0, 0]])</span>
</pre></div>
</div>
<dl class="method">
<dt id="mdptoolbox.mdp.FiniteHorizon.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#FiniteHorizon.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.FiniteHorizon.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.FiniteHorizon.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.FiniteHorizon.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.FiniteHorizon.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.FiniteHorizon.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.MDP">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">MDP</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>epsilon</em>, <em>max_iter</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">builtins.object</span></tt></p>
<p>A Markov Decision Problem.</p>
<p>Let <tt class="docutils literal"><span class="pre">S</span></tt> = the number of states, and <tt class="docutils literal"><span class="pre">A</span></tt> = the number of acions.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. These can be defined in a variety of
ways. The simplest is a numpy array that has the shape <tt class="docutils literal"><span class="pre">(A,</span> <span class="pre">S,</span> <span class="pre">S)</span></tt>,
though there are other possibilities. It can be a tuple or list or
numpy object array of length <tt class="docutils literal"><span class="pre">A</span></tt>, where each element contains a numpy
array or matrix that has the shape <tt class="docutils literal"><span class="pre">(S,</span> <span class="pre">S)</span></tt>. This “list of matrices”
form is useful when the transition matrices are sparse as
<tt class="docutils literal"><span class="pre">scipy.sparse.csr_matrix</span></tt> matrices can be used. In summary, each
action’s transition matrix must be indexable like <tt class="docutils literal"><span class="pre">transitions[a]</span></tt>
where <tt class="docutils literal"><span class="pre">a</span></tt> ∈ {0, 1...A-1}, and <tt class="docutils literal"><span class="pre">transitions[a]</span></tt> returns an <tt class="docutils literal"><span class="pre">S</span></tt> ×
<tt class="docutils literal"><span class="pre">S</span></tt> array-like object.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. Like the transition matrices, these can
also be defined in a variety of ways. Again the simplest is a numpy
array that has the shape <tt class="docutils literal"><span class="pre">(S,</span> <span class="pre">A)</span></tt>, <tt class="docutils literal"><span class="pre">(S,)</span></tt> or <tt class="docutils literal"><span class="pre">(A,</span> <span class="pre">S,</span> <span class="pre">S)</span></tt>. A list
of lists can be used, where each inner list has length <tt class="docutils literal"><span class="pre">S</span></tt> and the
outer list has length <tt class="docutils literal"><span class="pre">A</span></tt>. A list of numpy arrays is possible where
each inner array can be of the shape <tt class="docutils literal"><span class="pre">(S,)</span></tt>, <tt class="docutils literal"><span class="pre">(S,</span> <span class="pre">1)</span></tt>, <tt class="docutils literal"><span class="pre">(1,</span> <span class="pre">S)</span></tt>
or <tt class="docutils literal"><span class="pre">(S,</span> <span class="pre">S)</span></tt>. Also <tt class="docutils literal"><span class="pre">scipy.sparse.csr_matrix</span></tt> can be used instead of
numpy arrays. In addition, the outer list can be replaced by any object
that can be indexed like <tt class="docutils literal"><span class="pre">reward[a]</span></tt> such as a tuple or numpy object
array of length <tt class="docutils literal"><span class="pre">A</span></tt>.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. The per time-step discount factor on future rewards.
Valid values are greater than 0 upto and including 1. If the discount
factor is 1, then convergence is cannot be assumed and a warning will
be displayed. Subclasses of <tt class="docutils literal"><span class="pre">MDP</span></tt> may pass <tt class="docutils literal"><span class="pre">None</span></tt> in the case where
the algorithm does not use a discount factor.</li>
<li><strong>epsilon</strong> (<em>float</em>) – Stopping criterion. The maximum change in the value function at each
iteration is compared against <tt class="docutils literal"><span class="pre">epsilon</span></tt>. Once the change falls below
this value, then the value function is considered to have converged to
the optimal value function. Subclasses of <tt class="docutils literal"><span class="pre">MDP</span></tt> may pass <tt class="docutils literal"><span class="pre">None</span></tt> in
the case where the algorithm does not use an epsilon-optimal stopping
criterion.</li>
<li><strong>max_iter</strong> (<em>int</em>) – Maximum number of iterations. The algorithm will be terminated once
this many iterations have elapsed. This must be greater than 0 if
specified. Subclasses of <tt class="docutils literal"><span class="pre">MDP</span></tt> may pass <tt class="docutils literal"><span class="pre">None</span></tt> in the case where
the algorithm does not use a maximum number of iterations.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.P">
<tt class="descname">P</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.P" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array</em></p>
<p>Transition probability matrices.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.R">
<tt class="descname">R</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.R" title="Permalink to this definition">¶</a></dt>
<dd><p><em>array</em></p>
<p>Reward vectors.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.V">
<tt class="descname">V</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.V" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tuple</em></p>
<p>The optimal value function. Each element is a float corresponding to
the expected value of being in that state assuming the optimal policy
is followed.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.discount">
<tt class="descname">discount</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.discount" title="Permalink to this definition">¶</a></dt>
<dd><p><em>float</em></p>
<p>The discount rate on future rewards.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.max_iter">
<tt class="descname">max_iter</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.max_iter" title="Permalink to this definition">¶</a></dt>
<dd><p><em>int</em></p>
<p>The maximum number of iterations.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.policy">
<tt class="descname">policy</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.policy" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tuple</em></p>
<p>The optimal policy.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.time">
<tt class="descname">time</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.time" title="Permalink to this definition">¶</a></dt>
<dd><p><em>float</em></p>
<p>The time used to converge to the optimal policy.</p>
</dd></dl>

<dl class="attribute">
<dt id="mdptoolbox.mdp.MDP.verbose">
<tt class="descname">verbose</tt><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.verbose" title="Permalink to this definition">¶</a></dt>
<dd><p><em>boolean</em></p>
<p>Whether verbose output should be displayed or not.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.MDP.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Implemented in child classes as the main algorithm loop. Raises an
exception if it has not been overridden.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.MDP.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP.setSilent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Turn the verbosity off</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.MDP.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP.setVerbose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Turn the verbosity on</p>
</dd></dl>

<dl class="method">
<dt>
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP.run"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Raises error because child classes should implement this function.</p>
</dd></dl>

<dl class="method">
<dt>
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP.setSilent"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt>
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#MDP.setVerbose"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.PolicyIteration">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">PolicyIteration</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>policy0=None</em>, <em>max_iter=1000</em>, <em>eval_type=0</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#PolicyIteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="mdptoolbox.mdp.MDP"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.MDP</span></tt></a></p>
<p>A discounted MDP solved using the policy iteration algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.</li>
<li><strong>policy0</strong> (<em>array, optional</em>) – Starting policy.</li>
<li><strong>max_iter</strong> (<em>int, optional</em>) – Maximum number of iterations. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details. Default is 1000.</li>
<li><strong>eval_type</strong> (<em>int or string, optional</em>) – Type of function used to evaluate policy. 0 or “matrix” to solve as a
set of linear equations. 1 or “iterative” to solve iteratively.
Default: 0.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attributes</strong> (<em>Data</em>) – </li>
<li><strong>—————</strong> – </li>
<li><strong>V</strong> (<em>tuple</em>) – value function</li>
<li><strong>policy</strong> (<em>tuple</em>) – optimal policy</li>
<li><strong>iter</strong> (<em>int</em>) – number of done iterations</li>
<li><strong>time</strong> (<em>float</em>) – used CPU time</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>In verbose mode, at each iteration, displays the number
of differents actions between policy n-1 and n</p>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span><span class="o">,</span> <span class="nn">mdptoolbox.example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">PolicyIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">forest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">PolicyIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">26.244000000000014</span><span class="p">,</span> <span class="mf">29.484000000000016</span><span class="p">,</span> <span class="mf">33.484000000000016</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">pi</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pi</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(0, 0, 0)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mdptoolbox.mdp.PolicyIteration.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#PolicyIteration.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIteration.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.PolicyIteration.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIteration.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.PolicyIteration.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIteration.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.PolicyIterationModified">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">PolicyIterationModified</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>epsilon=0.01</em>, <em>max_iter=10</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#PolicyIterationModified"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIterationModified" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIteration" title="mdptoolbox.mdp.PolicyIteration"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.PolicyIteration</span></tt></a></p>
<p>A discounted MDP  solved using a modifified policy iteration algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.</li>
<li><strong>epsilon</strong> (<em>float, optional</em>) – Stopping criterion. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details. Default: 0.01.</li>
<li><strong>max_iter</strong> (<em>int, optional</em>) – Maximum number of iterations. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details. Default is 10.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attributes</strong> (<em>Data</em>) – </li>
<li><strong>—————</strong> – </li>
<li><strong>V</strong> (<em>tuple</em>) – value function</li>
<li><strong>policy</strong> (<em>tuple</em>) – optimal policy</li>
<li><strong>iter</strong> (<em>int</em>) – number of done iterations</li>
<li><strong>time</strong> (<em>float</em>) – used CPU time</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span><span class="o">,</span> <span class="nn">mdptoolbox.example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">forest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pim</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">PolicyIterationModified</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pim</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pim</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(0, 0, 0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">21.81408652334702</span><span class="p">,</span> <span class="mf">25.054086523347017</span><span class="p">,</span> <span class="mf">29.054086523347017</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">pim</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="method">
<dt id="mdptoolbox.mdp.PolicyIterationModified.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#PolicyIterationModified.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIterationModified.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.PolicyIterationModified.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIterationModified.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.PolicyIterationModified.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.PolicyIterationModified.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.QLearning">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">QLearning</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>n_iter=10000</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#QLearning"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.QLearning" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="mdptoolbox.mdp.MDP"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.MDP</span></tt></a></p>
<p>A discounted MDP solved using the Q learning algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.</li>
<li><strong>n_iter</strong> (<em>int, optional</em>) – Number of iterations to execute. This is ignored unless it is an
integer greater than the default value. Defaut: 10,000.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attributes</strong> (<em>Data</em>) – </li>
<li><strong>—————</strong> – </li>
<li><strong>Q</strong> (<em>array</em>) – learned Q matrix (SxA)</li>
<li><strong>V</strong> (<em>tuple</em>) – learned value function (S).</li>
<li><strong>policy</strong> (<em>tuple</em>) – learned optimal policy (S).</li>
<li><strong>mean_discrepancy</strong> (<em>array</em>) – Vector of V discrepancy mean over 100 iterations. Then the length of
this vector for the default value of N is 100 (N/100).</li>
<li><strong>Examples</strong> – </li>
<li><strong>———</strong> – </li>
<li><strong># These examples are reproducible only if random seed is set to 0 in</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong># both the random and numpy.random modules.</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>import numpy as np</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>import mdptoolbox, mdptoolbox.example</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>np.random.seed(0)</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>P, R = mdptoolbox.example.forest()</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>ql = mdptoolbox.mdp.QLearning(P, R, 0.96)</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>ql.run()</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>ql.Q</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>11.198909  ,  10.34652034],</strong> (<em>array([[</em>) – [ 10.74229967,  11.74105792],
[  2.86980001,  12.25973286]])</li>
<li><strong>expected = (11.198908998901134, 11.741057920409865, 12.259732864170232)</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>all(expected[k] - ql.V[k] &lt; 1e-12 for k in range(len(expected)))</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>True</strong> – </li>
<li><strong>ql.policy</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>1, 1)</strong> (<em>(0,</em>) – </li>
<li><strong>import mdptoolbox</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>import numpy as np</strong> – </li>
<li><strong>P = np.array([[[0.5, 0.5],[0.8, 0.2]],[[0, 1],[0.1, 0.9]]])</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>R = np.array([[5, 10], [-1, 2]])</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>np.random.seed(0)</strong> – </li>
<li><strong>ql = mdptoolbox.mdp.QLearning(P, R, 0.9)</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>ql.run()</strong> – </li>
<li><strong>ql.Q</strong> – </li>
<li><strong>33.33010866,  40.82109565],</strong> (<em>array([[</em>) – [ 34.37431041,  29.67236845]])</li>
<li><strong>expected = (40.82109564847122, 34.37431040682546)</strong> (<em>&gt;&gt;&gt;</em>) – </li>
<li><strong>all(expected[k] - ql.V[k] &lt; 1e-12 for k in range(len(expected)))</strong> – </li>
<li><strong>True</strong> – </li>
<li><strong>ql.policy</strong> – </li>
<li><strong>0)</strong> (<em>(1,</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mdptoolbox.mdp.QLearning.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#QLearning.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.QLearning.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.QLearning.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.QLearning.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.QLearning.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.QLearning.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.RelativeValueIteration">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">RelativeValueIteration</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>epsilon=0.01</em>, <em>max_iter=1000</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#RelativeValueIteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.RelativeValueIteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="mdptoolbox.mdp.MDP"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.MDP</span></tt></a></p>
<p>A MDP solved using the relative value iteration algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>epsilon</strong> (<em>float, optional</em>) – Stopping criterion. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details. Default: 0.01.</li>
<li><strong>max_iter</strong> (<em>int, optional</em>) – Maximum number of iterations. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details. Default: 1000.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attributes</strong> (<em>Data</em>) – </li>
<li><strong>—————</strong> – </li>
<li><strong>policy</strong> (<em>tuple</em>) – epsilon-optimal policy</li>
<li><strong>average_reward</strong> (<em>tuple</em>) – average reward of the optimal policy</li>
<li><strong>cpu_time</strong> (<em>float</em>) – used CPU time</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>In verbose mode, at each iteration, displays the span of U variation
and the condition which stopped iterations : epsilon-optimum policy found
or maximum number of iterations reached.</p>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span><span class="o">,</span> <span class="nn">mdptoolbox.example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">forest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">RelativeValueIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">average_reward</span>
<span class="go">3.2399999999999993</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(0, 0, 0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">iter</span>
<span class="go">4</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]],[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">RelativeValueIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">3.885235246411831</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">rvi</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">average_reward</span>
<span class="go">3.8852352464118312</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(1, 0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvi</span><span class="o">.</span><span class="n">iter</span>
<span class="go">29</span>
</pre></div>
</div>
<dl class="method">
<dt id="mdptoolbox.mdp.RelativeValueIteration.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#RelativeValueIteration.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.RelativeValueIteration.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.RelativeValueIteration.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.RelativeValueIteration.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.RelativeValueIteration.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.RelativeValueIteration.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.ValueIteration">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">ValueIteration</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>epsilon=0.01</em>, <em>max_iter=1000</em>, <em>initial_value=0</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#ValueIteration"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIteration" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.MDP" title="mdptoolbox.mdp.MDP"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.MDP</span></tt></a></p>
<p>A discounted MDP solved using the value iteration algorithm.</p>
<p>ValueIteration applies the value iteration algorithm to solve a
discounted MDP. The algorithm consists of solving Bellman’s equation
iteratively.
Iteration is stopped when an epsilon-optimal policy is found or after a
specified number (<tt class="docutils literal"><span class="pre">max_iter</span></tt>) of iterations.
This function uses verbose and silent modes. In verbose mode, the function
displays the variation of <tt class="docutils literal"><span class="pre">V</span></tt> (the value function) for each iteration and
the condition which stopped the iteration: epsilon-policy found or maximum
number of iterations reached.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.</li>
<li><strong>epsilon</strong> (<em>float, optional</em>) – Stopping criterion. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.  Default: 0.01.</li>
<li><strong>max_iter</strong> (<em>int, optional</em>) – Maximum number of iterations. If the value given is greater than a
computed bound, a warning informs that the computed bound will be used
instead. By default, if <tt class="docutils literal"><span class="pre">discount</span></tt> is not equal to 1, a bound for
<tt class="docutils literal"><span class="pre">max_iter</span></tt> is computed, otherwise <tt class="docutils literal"><span class="pre">max_iter</span></tt> = 1000. See the
documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for further details.</li>
<li><strong>initial_value</strong> (<em>array, optional</em>) – The starting value function. Default: a vector of zeros.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attributes</strong> (<em>Data</em>) – </li>
<li><strong>—————</strong> – </li>
<li><strong>V</strong> (<em>tuple</em>) – The optimal value function.</li>
<li><strong>policy</strong> (<em>tuple</em>) – The optimal policy function. Each element is an integer corresponding
to an action which maximises the value function in that state.</li>
<li><strong>iter</strong> (<em>int</em>) – The number of iterations taken to complete the computation.</li>
<li><strong>time</strong> (<em>float</em>) – The amount of CPU time used to run the algorithm.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="mdptoolbox.mdp.ValueIteration.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#ValueIteration.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIteration.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Do the algorithm iteration.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.ValueIteration.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIteration.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the instance to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.ValueIteration.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIteration.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the instance to verbose mode.</p>
</dd></dl>

<p class="rubric">Notes</p>
<p>In verbose mode, at each iteration, displays the variation of V
and the condition which stopped iterations: epsilon-optimum policy found
or maximum number of iterations reached.</p>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span><span class="o">,</span> <span class="nn">mdptoolbox.example</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">forest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">ValueIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.96</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">verbose</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">5.93215488</span><span class="p">,</span> <span class="mf">9.38815488</span><span class="p">,</span> <span class="mf">13.38815488</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">vi</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(0, 0, 0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">iter</span>
<span class="go">4</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]],[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">ValueIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">40.048625392716815</span><span class="p">,</span> <span class="mf">33.65371175967546</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">vi</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(1, 0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">iter</span>
<span class="go">26</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span> <span class="k">as</span> <span class="n">sparse</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sparse</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">ValueIteration</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">40.048625392716815</span><span class="p">,</span> <span class="mf">33.65371175967546</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">vi</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vi</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(1, 0)</span>
</pre></div>
</div>
<dl class="method">
<dt>
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#ValueIteration.run"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<tt class="descname">setSilent</tt><big>(</big><big>)</big></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt>
<tt class="descname">setVerbose</tt><big>(</big><big>)</big></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="mdptoolbox.mdp.ValueIterationGS">
<em class="property">class </em><tt class="descclassname">mdptoolbox.mdp.</tt><tt class="descname">ValueIterationGS</tt><big>(</big><em>transitions</em>, <em>reward</em>, <em>discount</em>, <em>epsilon=0.01</em>, <em>max_iter=10</em>, <em>initial_value=0</em>, <em>skip_check=False</em><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#ValueIterationGS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIterationGS" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIteration" title="mdptoolbox.mdp.ValueIteration"><tt class="xref py py-class docutils literal"><span class="pre">mdptoolbox.mdp.ValueIteration</span></tt></a></p>
<p>A discounted MDP solved using the value iteration Gauss-Seidel algorithm.</p>
<table class="docutils field-list" frame="void" rules="none">
<colgroup><col class="field-name">
<col class="field-body">
</colgroup><tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>transitions</strong> (<em>array</em>) – Transition probability matrices. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
class for details.</li>
<li><strong>reward</strong> (<em>array</em>) – Reward matrices or vectors. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class
for details.</li>
<li><strong>discount</strong> (<em>float</em>) – Discount factor. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details.</li>
<li><strong>epsilon</strong> (<em>float, optional</em>) – Stopping criterion. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt> class for
details. Default: 0.01.</li>
<li><strong>max_iter</strong> (<em>int, optional</em>) – Maximum number of iterations. See the documentation for the <tt class="docutils literal"><span class="pre">MDP</span></tt>
and <tt class="docutils literal"><span class="pre">ValueIteration</span></tt> classes for details. Default: computed.</li>
<li><strong>initial_value</strong> (<em>array, optional</em>) – The starting value function. Default: a vector of zeros.</li>
<li><strong>skip_check</strong> (<em>bool</em>) – By default we run a check on the <tt class="docutils literal"><span class="pre">transitions</span></tt> and <tt class="docutils literal"><span class="pre">rewards</span></tt>
arguments to make sure they describe a valid MDP. You can set this
argument to True in order to skip this check.</li>
<li><strong>Attribues</strong> (<em>Data</em>) – </li>
<li><strong>————–</strong> – </li>
<li><strong>policy</strong> (<em>tuple</em>) – epsilon-optimal policy</li>
<li><strong>iter</strong> (<em>int</em>) – number of done iterations</li>
<li><strong>time</strong> (<em>float</em>) – used CPU time</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>In verbose mode, at each iteration, displays the variation of V
and the condition which stopped iterations: epsilon-optimum policy found
or maximum number of iterations reached.</p>
<p class="rubric">Examples</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mdptoolbox.example</span><span class="o">,</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">P</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">example</span><span class="o">.</span><span class="n">forest</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vigs</span> <span class="o">=</span> <span class="n">mdptoolbox</span><span class="o">.</span><span class="n">mdp</span><span class="o">.</span><span class="n">ValueIterationGS</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vigs</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="mf">25.5833879767579</span><span class="p">,</span> <span class="mf">28.830654635546928</span><span class="p">,</span> <span class="mf">32.83065463554693</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">all</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">vigs</span><span class="o">.</span><span class="n">V</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">1e-12</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">expected</span><span class="p">)))</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vigs</span><span class="o">.</span><span class="n">policy</span>
<span class="go">(0, 0, 0)</span>
</pre></div>
</div>
<dl class="method">
<dt id="mdptoolbox.mdp.ValueIterationGS.run">
<tt class="descname">run</tt><big>(</big><big>)</big><a class="reference internal" href="https://pymdptoolbox.readthedocs.io/en/latest/_modules/mdptoolbox/mdp.html#ValueIterationGS.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIterationGS.run" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.ValueIterationGS.setSilent">
<tt class="descname">setSilent</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIterationGS.setSilent" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to silent mode.</p>
</dd></dl>

<dl class="method">
<dt id="mdptoolbox.mdp.ValueIterationGS.setVerbose">
<tt class="descname">setVerbose</tt><big>(</big><big>)</big><a class="headerlink" href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html#mdptoolbox.mdp.ValueIterationGS.setVerbose" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the MDP algorithm to verbose mode.</p>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="https://pymdptoolbox.readthedocs.io/en/latest/api/util.html" class="btn btn-neutral float-right" title="Markov Decision Process (MDP) Toolbox: util module">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdptoolbox.html" class="btn btn-neutral" title="Markov Decision Process (MDP) Toolbox"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr><div><div id="rtd-mroz7ad4" class="ethical-rtd"></div></div>

  <div role="contentinfo">
    <p>
        © Copyright 2015, Steven A W Cordwell.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org/">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions"><!-- Inserted RTD Footer -->

<div class="injected">

  

      
      
      
      <dl>
        <dt>Versions</dt>
        
         <strong> 
        <dd><a href="https://pymdptoolbox.readthedocs.io/en/latest/api/mdp.html">latest</a></dd>
         </strong> 
        
        
        <dd><a href="https://pymdptoolbox.readthedocs.io/en/stable/api/mdp.html">stable</a></dd>
        
        
      </dl>
      
      

      
      
      <dl>
        <dt>Downloads</dt>
        
        <dd><a href="https://readthedocs.org/projects/pymdptoolbox/downloads/pdf/latest/">PDF</a></dd>
        
        <dd><a href="https://readthedocs.org/projects/pymdptoolbox/downloads/htmlzip/latest/">HTML</a></dd>
        
        <dd><a href="https://readthedocs.org/projects/pymdptoolbox/downloads/epub/latest/">Epub</a></dd>
        
      </dl>
      
      

      
      <dl>
        <!-- These are kept as relative links for internal installs that are http -->
        <dt>On Read the Docs</dt>
        <dd>
          <a href="https://readthedocs.org/projects/pymdptoolbox/">Project Home</a>
        </dd>
        <dd>
          <a href="https://readthedocs.org/projects/pymdptoolbox/builds/">Builds</a>
        </dd>
        <dd>
          <a href="https://readthedocs.org/projects/pymdptoolbox/downloads/">Downloads</a>
        </dd>
      </dl>
      

      

      
      <dl>
        <dt>On GitHub</dt>
        <dd>
          <a href="https://github.com/sawcordwell/pymdptoolbox/blob/master/docs/api/mdp.rst">View</a>
        </dd>
        
        <dd>
          <a href="https://github.com/sawcordwell/pymdptoolbox/edit/master/docs/api/mdp.rst">Edit</a>
        </dd>
        
      </dl>
      
      

      
      <dl>
        <dt>Search</dt>
        <dd>
          <div style="padding: 6px;">
            <form id="flyout-search-form" class="wy-form" target="_blank" action="https://readthedocs.org/projects/pymdptoolbox/search/" method="get">
              <input type="text" name="q" placeholder="Search docs">
              </form>
          </div>
        </dd>
      </dl>
      



      <hr>
      
        <small>
          <span>Hosted by <a href="https://readthedocs.org/">Read the Docs</a></span>
          <span> · </span>
          <a href="https://docs.readthedocs.io/page/privacy-policy.html">Privacy Policy</a>
        </small>
      

      

</div>
</div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'4.0-b4',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="./mdp_toolbox_files/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="./mdp_toolbox_files/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="./mdp_toolbox_files/underscore.js"></script>
      <script type="text/javascript" src="./mdp_toolbox_files/doctools.js"></script>
      <script type="text/javascript" src="./mdp_toolbox_files/readthedocs-doc-embed.js"></script>
      <script type="text/javascript" src="./mdp_toolbox_files/MathJax.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   


<div id="rtd-y9w2j979"></div></body></html>